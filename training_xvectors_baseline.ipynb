{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-patrick",
   "metadata": {},
   "source": [
    "# Training baseline architecture (x-vectors 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-projector",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.nn_models.xvectors_baseline import *\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.manifold import TSNE\n",
    "from pathlib import Path\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-trauma",
   "metadata": {},
   "source": [
    "**Configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "training_data = Path(\"/home/joey/School/KNN/speaker-identification/data/vox1_dev/\")\n",
    "testing_data = Path(\"/home/joey/School/KNN/speaker-identification/data/vox1_test/\")\n",
    "model_params = Path(\"/home/joey/School/KNN/speaker-identification/model_params.pt\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 50\n",
    "batch_size = 2048\n",
    "chunk_size = 24\n",
    "\n",
    "# model declaration:\n",
    "speakers_count = len(listdir(training_data))\n",
    "model = XVectorsBaseline(speakers_count, chunk_size).to(device)\n",
    "\n",
    "if model_params.is_file():\n",
    "    model.load_state_dict(torch.load(model_params))\n",
    "    print(\"Model parameters were loaded!\")\n",
    "\n",
    "# loss and optimizer selection:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# create training dataset and dataloader:\n",
    "train_dataset = create_training_mfcc_dataset(training_data, chunk_size)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-denver",
   "metadata": {},
   "source": [
    "**Training model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, model_params, epochs, train_dataloader, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-hanging",
   "metadata": {},
   "source": [
    "**Visual evaluation of model on testing data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvectors, labels = get_session_xvectors(model, testing_data, chunk_size, batch_size, device)\n",
    "xvectors_reduced = TSNE(n_components=2).fit_transform(np.array(xvectors))\n",
    "colors = [\"red\", \"blue\", \"green\", \"orange\", \"black\", \"pink\"]\n",
    "plt.scatter(xvectors_reduced[:,0], xvectors_reduced[:,1], c=[colors[l] for l in labels])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
